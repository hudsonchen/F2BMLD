{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a9b3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(\"/home/zongchen/F2BMLD\")\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import sys\n",
    "sys.path.append(\"/home/zongchen/F2BMLD\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Sequence, Tuple\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath, amsfonts}')\n",
    "\n",
    "# plt.rc('font', family='Arial', size=12)\n",
    "plt.rc('axes', titlesize=16, labelsize=18, grid=True)\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('legend', fontsize=18, frameon=False)\n",
    "plt.rc('xtick', labelsize=14, direction='in')\n",
    "plt.rc('ytick', labelsize=14, direction='in')\n",
    "plt.rc('figure', figsize=(6, 4), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11888b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from methods import dfiv, f2bmld\n",
    "import utils\n",
    "from utils import load_pretrained_dqn\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "env_spec = {\n",
    "        \"obs_dim\": 4,\n",
    "        \"act_dim\": 2,\n",
    "        \"obs_space\": env.observation_space,\n",
    "        \"act_space\": env.action_space,\n",
    "    }\n",
    "\n",
    "value_layer_sizes = \"50\"\n",
    "instrumental_layer_sizes= \"50\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "value_func, instrumental_feature = dfiv.bsuite_network.make_value_func_bsuite(\n",
    "    env_spec, value_layer_sizes, instrumental_layer_sizes, device\n",
    ")\n",
    "\n",
    "policy_dqn = load_pretrained_dqn(\"policy_net.pth\", device)\n",
    "\n",
    "treatment_net = f2bmld.bsuite_network.TreatmentNetwork(env_spec, layer_sizes=[50, 1]).to(device)\n",
    "\n",
    "def target_policy(obs_batch: torch.Tensor, policy_dqn: torch.nn.Module) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        return policy_dqn(obs_batch).argmax(dim=-1)\n",
    "\n",
    "class RandomActionWrapper(gym.Wrapper):\n",
    "    \"\"\"With probability `eps`, take a random action instead of the policy's action.\"\"\"\n",
    "    def __init__(self, env, eps=0.1):\n",
    "        super().__init__(env)\n",
    "        self.eps = eps\n",
    "\n",
    "    def step(self, action):\n",
    "        if np.random.rand() < self.eps:\n",
    "            action = self.env.action_space.sample()\n",
    "        return self.env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f18bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(environment, policy, value_func, num_init_samples, device):\n",
    "    q0s = []\n",
    "    for _ in tqdm(range(num_init_samples)):\n",
    "        obs, _ = environment.reset()\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        action = policy(obs_tensor)\n",
    "        q0 = value_func(obs_tensor, action).item()\n",
    "        q0s.append(q0)\n",
    "\n",
    "    q0s = np.array(q0s)\n",
    "    return q0s.mean()\n",
    "\n",
    "\n",
    "def estimate_true_value(policy, environment, discount=0.99, \n",
    "                        num_episodes=100, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Estimate the true discounted return of a policy by Monte Carlo rollouts.\n",
    "\n",
    "    Args:\n",
    "        policy: Callable/nn.Module mapping obs -> action (PyTorch).\n",
    "        environment: Gym-like env with reset() and step().\n",
    "        discount: float, discount factor.\n",
    "        num_episodes: int, number of episodes to average over.\n",
    "        device: str, \"cpu\" or \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        mean_return: average discounted return across episodes.\n",
    "        stderr_return: standard error of returns.\n",
    "    \"\"\"\n",
    "    returns = []\n",
    "    for _ in tqdm(range(num_episodes)):\n",
    "        obs, _ = environment.reset()\n",
    "        done, ep_return, t = False, 0.0, 0\n",
    "\n",
    "        while not done:\n",
    "            obs_tensor = torch.tensor(obs, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            action = policy(obs_tensor)\n",
    "\n",
    "            # handle discrete vs continuous\n",
    "            if isinstance(action, torch.Tensor):\n",
    "                if action.numel() == 1:  # discrete scalar\n",
    "                    action = int(action.item())\n",
    "                else:  # e.g. policy outputs logits/probs\n",
    "                    action = int(torch.argmax(action, dim=-1).item())\n",
    "\n",
    "            next_obs, reward, terminated, truncated, _ = environment.step(action)\n",
    "            done = terminated or truncated\n",
    "            ep_return += (discount ** t) * reward\n",
    "            obs = next_obs\n",
    "            t += 1\n",
    "\n",
    "        returns.append(ep_return)\n",
    "\n",
    "    mean_return = float(np.mean(returns))\n",
    "    return mean_return, float(np.std(returns)) / np.sqrt(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4939771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.58it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2837.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.78299846692262 2.2849791419654695\n",
      "89.08661341094971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.70it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3195.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.17712927902214 2.336299925968271\n",
      "89.07414571380615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed_list = [0]\n",
    "env_noise_list = [0.1]\n",
    "policy_noise_list = [0.0, 0.2]\n",
    "# reg = \"0.0001\"\n",
    "reg = \"1e-05\"\n",
    "\n",
    "for seed in seed_list:\n",
    "    for env_noise in env_noise_list:\n",
    "        for policy_noise in policy_noise_list:\n",
    "            ### F2BMLD\n",
    "            path = f\"/home/zongchen/F2BMLD/results/f2bmld_env_noise_{env_noise}__policy_noise_{policy_noise}\"\n",
    "            path += f\"__lagrange_0.3__stage1_reg_{reg}__stage2_reg_{reg}__treat_lr_0.001\"\n",
    "            path += f\"__instr_lr_0.001__instr_iter_10__instr_tilde_iter_10__bs_32__seed_{seed}/treatment_net.pth\"\n",
    "            treatment_net.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "            if env_noise > 0.0:\n",
    "                environment = RandomActionWrapper(env, eps=env_noise)\n",
    "            else:\n",
    "                environment = env\n",
    "            truth_value, truth_value_ste = estimate_true_value(\n",
    "                partial(target_policy, policy_dqn=policy_dqn), environment, discount=0.99, num_episodes=100, device=device\n",
    "            )\n",
    "\n",
    "            estimate_value = eval(environment, partial(target_policy, policy_dqn=policy_dqn), treatment_net, \n",
    "                                  num_init_samples=1000,device=device)\n",
    "\n",
    "            print(truth_value, truth_value_ste)\n",
    "            print(estimate_value)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "F2BMLD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
